{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SearchEngine.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aldolipani/SearchEngine/blob/master/SearchEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o51Jx9eer3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import codecs\n",
        "import nltk\n",
        "import string\n",
        "import math\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm_notebook\n",
        "from bs4 import BeautifulSoup, Tag\n",
        "from google.colab import drive\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "path = None\n",
        "if IN_COLAB:\n",
        "  drive.mount('/content/gdrive')\n",
        "  path = \"./gdrive/My Drive/SearchEngine/\"\n",
        "else:\n",
        "  path = \"./SearchEngine/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2lBOIeyr_1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"$path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhQ-zANIgMd7",
        "colab_type": "text"
      },
      "source": [
        "# Download Test Collection\n",
        "Note that you need to substitute your GitLab username and password in order to download the test collection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPTmL_mmRNJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(path + \"test-collection\"):\n",
        "  !rm -fr \"$path\"/test-collection\n",
        "  !git clone https://username:password@gitlab.com/aldolipani/adhoc8.git\n",
        "  !mv adhoc8 \"$path\"/test-collection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeK3g0bv6gZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"$path\"/test-collection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FALBUb3S6vZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"$path\"/test-collection/Collection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BikBxHIhA-Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"$path\"/test-collection/Topics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njoKJ2thBA2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"$path\"/test-collection/QRels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPAaQ_1NffnY",
        "colab_type": "text"
      },
      "source": [
        "# Parse Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcbIY1yHPqU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "collection = {}\n",
        "\n",
        "if not os.path.exists(path + \"collection.npy\"):\n",
        "  for file_name in tqdm_notebook(list(glob.iglob(path + \"test-collection/Collection/**\", recursive = True))):\n",
        "    if os.path.isfile(file_name):\n",
        "      text = \"<DOCS>\" + codecs.open(file_name, \"r\", \"iso-8859-1\").read() + \"</DOCS>\"\n",
        "      parsed_text = BeautifulSoup(text)\n",
        "      for doc in parsed_text.docs:\n",
        "        id = None\n",
        "        text = []\n",
        "        for field in doc:\n",
        "          if isinstance(field, Tag):\n",
        "            if field.name == \"docno\":\n",
        "              id = field.text.strip()\n",
        "            else:\n",
        "              text.append(field.text.strip())\n",
        "        collection[id] = \"\\n\".join(text)\n",
        "      \n",
        "  np.save(path + \"collection.npy\", collection)\n",
        "else:\n",
        "  print(\"loading\", path + \"collection.npy\")\n",
        "  collection = np.load(path + \"collection.npy\", allow_pickle=True).all()\n",
        "\n",
        "print(str(len(collection)) + \" documents read!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK-CqkzVzhO1",
        "colab_type": "text"
      },
      "source": [
        "#Create Direct Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgrw-rbFKJwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "direct_index = {}\n",
        "\n",
        "ps = nltk.stem.PorterStemmer()\n",
        "preprocess_cache = {}\n",
        "def preprocess(token):\n",
        "  if token not in preprocess_cache:\n",
        "    preprocess_cache[token] = ps.stem(token.lower())\n",
        "  return preprocess_cache[token]\n",
        "\n",
        "if not os.path.exists(path + \"direct_index.npy\"):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  for doc in tqdm_notebook(collection):\n",
        "    text = collection[doc]\n",
        "    bag_or_words = {}\n",
        "    for token in nltk.word_tokenize(text):\n",
        "      if not (token in string.punctuation or token in stop_words):\n",
        "        token = preprocess(token)\n",
        "        if token not in bag_or_words:\n",
        "          bag_or_words[token] = 1\n",
        "        else:\n",
        "          bag_or_words[token] += 1\n",
        "    direct_index[doc] = bag_or_words\n",
        "\n",
        "  np.save(path + \"direct_index.npy\", direct_index)\n",
        "else:\n",
        "  print(\"loading\", path + \"direct_index.npy\")\n",
        "  direct_index = np.load(path + \"direct_index.npy\", allow_pickle=True).all()\n",
        "  \n",
        "print(str(len(direct_index)) + \" documents in the direct index!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-TbDZrTtOPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del collection # free the memory used by the object collection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUCbGAjpduvt",
        "colab_type": "text"
      },
      "source": [
        "# Create Inverted Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnB-qRW9KLwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "inverted_index = {}\n",
        "\n",
        "if not os.path.exists(path + \"inverted_index.npy\"):\n",
        "  for doc in tqdm_notebook(direct_index):\n",
        "    bag_of_words = direct_index[doc]\n",
        "    for term in bag_of_words:\n",
        "      if term not in inverted_index:\n",
        "        inverted_index[term] = {}\n",
        "      inverted_index[term][doc] = bag_of_words[term]\n",
        "    if IN_COLAB:\n",
        "      direct_index[doc] = None\n",
        "  \n",
        "  np.save(path + \"inverted_index.npy\", inverted_index)\n",
        "else:\n",
        "  print(\"loading\", path + \"inverted_index.npy\")\n",
        "  inverted_index = np.load(path + \"inverted_index.npy\", allow_pickle=True).all()\n",
        "    \n",
        "print(str(len(inverted_index)) + \" words in the inverted index!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV6IOtbMtQV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del direct_index # free the memory used by the direct index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNmaUu1GVWqi",
        "colab_type": "text"
      },
      "source": [
        "# Read Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJy9T_tzHaRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%time\n",
        "queries = {}\n",
        "\n",
        "def preprocess(token):\n",
        "    ps = nltk.stem.PorterStemmer()\n",
        "    return ps.stem(token.lower())\n",
        "\n",
        "reTopic = re.compile(\"<num> Number: (\\d+)\")\n",
        "reTitle = re.compile(\"<title> (.+)\")\n",
        "\n",
        "topic = \"\"\n",
        "title = \"\"\n",
        "for line in codecs.open(path + \"test-collection/Topics/topicsTREC8Adhoc.txt\", \"r\", \"iso-8859-1\").readlines():\n",
        "    mTopic = reTopic.match(line)\n",
        "    mTitle = reTitle.match(line)\n",
        "    \n",
        "    if mTopic:\n",
        "        topic = mTopic.group(1).strip()\n",
        "    elif mTitle:\n",
        "        title = mTitle.group(1).strip()\n",
        "        tokens = nltk.word_tokenize(title)\n",
        "        queries[topic] = []\n",
        "        for token in tokens:\n",
        "            if token not in string.punctuation:\n",
        "                queries[topic].append(preprocess(token))\n",
        "\n",
        "print(str(len(queries)) + \" queries read!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXZ2qlgJVewK",
        "colab_type": "text"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoCekf0mFVJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "lds = {}\n",
        "for term in tqdm_notebook(inverted_index):\n",
        "  for doc in inverted_index[term]:\n",
        "    if doc not in lds:\n",
        "      lds[doc] = 0\n",
        "    lds[doc] += inverted_index[term][doc]\n",
        "\n",
        "D = len(lds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpnkvstbVfQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "runs = {}\n",
        "\n",
        "def lm(tf, df, term, doc):\n",
        "    pass\n",
        "\n",
        "#TF-IDF\n",
        "def tfidf(tf, df, term, doc):\n",
        "    return tf * math.log(D/df)\n",
        "\n",
        "#BM25\n",
        "def bm25(tf, df, term, doc):\n",
        "    ld = lds[doc]\n",
        "    return tf/(tf + 1.2*(0.7 + 0.3*ld/D)) * math.log(D/df)\n",
        "  \n",
        "score = bm25 \n",
        "\n",
        "for topic in queries:    \n",
        "    run = {}\n",
        "    for term in queries[topic]:\n",
        "        if term in inverted_index:\n",
        "            for doc in inverted_index[term]:\n",
        "                tf = inverted_index[term][doc]\n",
        "                df = len(inverted_index[term])\n",
        "                if not doc in run:\n",
        "                    run[doc] = bm25(tf, df, term, doc)\n",
        "                else:\n",
        "                    run[doc] = run[doc] + score(tf, df, term, doc)\n",
        "    \n",
        "    runs[topic] = run\n",
        "\n",
        "print(str(len(runs)) + \" runs retrieved!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIis5hlAVyLS",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F0UJzIjHhaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/usnistgov/trec_eval.git\n",
        "!(cd trec_eval && make)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwFmY8JZV4Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm run.txt\n",
        "\n",
        "with open('run.txt', 'a') as the_file:\n",
        "    for topic in queries:\n",
        "        n = 0\n",
        "        run = runs[topic]\n",
        "        for doc in sorted(run, key=run.get, reverse=True):\n",
        "            n = n + 1\n",
        "            if n == 1001:\n",
        "                break\n",
        "            the_file.write(str(topic) + \" Q0 \" + doc + \" \" + str(n) + \" \" + str(run[doc]) + \" run\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6gTIgPkVlJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./trec_eval/trec_eval -q \"$path\"/test-collection/QRels/qrels.trec8.adhoc.parts1-5 run.txt | grep ^map"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}