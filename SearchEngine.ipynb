{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SearchEngine.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aldolipani/SearchEngine/blob/master/SearchEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o51Jx9eer3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import codecs\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from tqdm import tqdm_notebook\n",
        "from bs4 import BeautifulSoup, Tag\n",
        "from google.colab import drive\n",
        "\n",
        "nltk.download('punkt')\n",
        "drive.mount('/content/gdrive')\n",
        "path = \"./gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPTmL_mmRNJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"./gdrive/My Drive/test-collection\"):\n",
        "  !rm -fr ./gdrive/My\\ Drive/test-collection\n",
        "  !git clone https://username:password@gitlab.com/aldolipani/adhoc8.git\n",
        "  !mv adhoc8 ./gdrive/My\\ Drive/test-collection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPAaQ_1NffnY",
        "colab_type": "text"
      },
      "source": [
        "# Parse Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcbIY1yHPqU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "collection = {}\n",
        "\n",
        "if not os.path.exists(path + \"collection.npy\"):\n",
        "  for file_name in tqdm_notebook(list(glob.iglob(path + \"test-collection/Collection/**\", recursive = True))):\n",
        "    if os.path.isfile(file_name):\n",
        "      text = \"<DOCS>\" + codecs.open(file_name, \"r\", \"iso-8859-1\").read() + \"</DOCS>\"\n",
        "      parsed_text = BeautifulSoup(text)\n",
        "      for doc in parsed_text.docs:\n",
        "        doc_id = None\n",
        "        doc_text = []\n",
        "        for field in doc:\n",
        "          if isinstance(field, Tag):\n",
        "            if field.name == \"docno\":\n",
        "              doc_id = field.text.strip()\n",
        "            else:\n",
        "              doc_text.append(field.text.strip())\n",
        "        collection[doc_id] = \"\\n\".join(doc_text)\n",
        "      \n",
        "  np.save(path + \"collection.npy\", collection)\n",
        "else:\n",
        "  collection = np.load(path + \"collection.npy\", allow_pickle=True).all()\n",
        "\n",
        "print(str(len(collection)) + \" documents read!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK-CqkzVzhO1",
        "colab_type": "text"
      },
      "source": [
        "#Create Direct Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgrw-rbFKJwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "direct_index = {}\n",
        "\n",
        "ps = nltk.stem.PorterStemmer()\n",
        "\n",
        "def preprocess(token):\n",
        "    return ps.stem(token.lower())\n",
        "\n",
        "if not os.path.exists(path + \"direct_index.npy\"):\n",
        "  for doc_id in tqdm_notebook(collection):\n",
        "    text = collection[doc_id]\n",
        "    bag_or_words = {}\n",
        "    for token in nltk.word_tokenize(text):\n",
        "      if token not in string.punctuation:\n",
        "        token = preprocess(token)\n",
        "        if token not in bag_or_words:\n",
        "          bag_or_words[token] = 1\n",
        "        else:\n",
        "          bag_or_words[token] += 1\n",
        "    direct_index[doc_id] = bag_or_words\n",
        "\n",
        "  np.save(path + \"direct_index.npy\", direct_index)\n",
        "else:\n",
        "  direct_index = np.load(path + \"direct_index.npy\", allow_pickle=True).all()\n",
        "\n",
        "print(str(len(direct_index)) + \" documents in the direct index!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnB-qRW9KLwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "inverted_index = {}\n",
        "\n",
        "if not os.path.exists(path + \"inverted_index.npy\"):\n",
        "  for doc_id in tqdm_notebook(direct_index):\n",
        "    vector = direct_index[doc_id]\n",
        "    for term in vector:\n",
        "      if term in inverted_index:\n",
        "        inverted_index[term].append({\"docId\":doc_id, \"tf\":vector[term]})\n",
        "      else:\n",
        "        inverted_index[term] = [{\"docId\":doc_id, \"tf\":vector[term]}]\n",
        "  \n",
        "  np.save(path + \"inverted_index.npy\", inverted_index)\n",
        "else:\n",
        "  inverted_index = np.load(path + \"inverted_index.npy\", allow_pickle=True).all()\n",
        "  \n",
        "print(str(len(inverted_index)) + \" words in the inverted index!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNmaUu1GVWqi",
        "colab_type": "text"
      },
      "source": [
        "# Read Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJy9T_tzHaRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%time\n",
        "queries = {}\n",
        "\n",
        "def preprocess(token):\n",
        "    ps = nltk.stem.PorterStemmer()\n",
        "    return ps.stem(token.lower())\n",
        "\n",
        "reTopicId = re.compile(\"<num> Number: (\\d+)\")\n",
        "reTitle = re.compile(\"<title> (.+)\")\n",
        "\n",
        "dir = '/Users/aldolipani/Dropbox/Dropbox/Shared/SOmer/datasets/TREC-8/AdHoc/Topics'\n",
        "\n",
        "topicId = \"\"\n",
        "title = \"\"\n",
        "for line in codecs.open(dir + \"/topicsTREC8Adhoc.txt\", \"r\", \"iso-8859-1\").readlines():\n",
        "    mTopicId = reTopicId.match(line)\n",
        "    mTitle = reTitle.match(line)\n",
        "    \n",
        "    if mTopicId:\n",
        "        topicId = mTopicId.group(1).strip()\n",
        "    elif mTitle:\n",
        "        title = mTitle.group(1).strip()\n",
        "        tokens = nltk.word_tokenize(title)\n",
        "        queries[topicId] = []\n",
        "        for token in tokens:\n",
        "            if token not in string.punctuation:\n",
        "                queries[topicId].append(preprocess(token))\n",
        "\n",
        "print(str(len(queries)) + \" queries read!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROlshGocVnj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lc = 0\n",
        "for doc in direct_index:\n",
        "    lc = lc + len(direct_index[doc])\n",
        "    \n",
        "D = len(direct_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXZ2qlgJVewK",
        "colab_type": "text"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpnkvstbVfQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "runs = {}\n",
        "\n",
        "def lm(tf, df, term, docId):\n",
        "    pass\n",
        "\n",
        "#TF-IDF\n",
        "def tfidf(tf, df, term, docId):\n",
        "    return tf * math.log(D/df)\n",
        "\n",
        "#BM25\n",
        "def bm25(tf, df, term, docId):\n",
        "    ld = len(direct_index[docId])\n",
        "    return tf/(tf + 1.2*(0.7 + 0.3*ld/D)) * math.log(D/df)\n",
        "\n",
        "for topic_id in queries:    \n",
        "    run = {}\n",
        "    for term in queries[topic_id]:\n",
        "        if term in inverted_index:\n",
        "            for post in inverted_index[term]:\n",
        "                docId = post['docId']\n",
        "                tf = post['tf']\n",
        "                df = len(inverted_index[term])\n",
        "                if not docId in run:\n",
        "                    run[docId] = score(tf, df, term, docId)\n",
        "                else:\n",
        "                    run[docId] = run[docId] + score(tf, df, term, docId)\n",
        "    \n",
        "    runs[topicId] = run\n",
        "\n",
        "print(str(len(runs)) + \" runs retrieved!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIis5hlAVyLS",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwFmY8JZV4Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test.txt', 'a') as the_file:\n",
        "    for topicId in queries:\n",
        "        n = 0\n",
        "        run = runs[topicId]\n",
        "        for doc in sorted(run, key=run.get, reverse=True):\n",
        "            n = n + 1\n",
        "            if n == 1001:\n",
        "                break\n",
        "            the_file.write(str(topicId) + \" Q0 \" + doc + \" \" + str(n) + \" \" + str(run[doc]) + \" test\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6gTIgPkVlJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "!trec_eval -q ./gdrive/My\\ Drive/test-collection/QRels/qrels.trec8.adhoc.parts1-5 test.txt | grep ^map"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}